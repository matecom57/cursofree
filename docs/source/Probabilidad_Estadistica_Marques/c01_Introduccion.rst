c01 Introduccion
================

## 1.1 Introduccion y Definicion de Estadistica

El término **estadistica** se derivó originalmente del vocablo "**estado**", porque ha sido función tradicional de los gobiernos centrales llevar registros de población, nacimiento,defunciones, profesiones, cosechas y muchas otras clases de cosas y actividades. Contar y medir estos hechos genera muchas clases de datos numéricos.

Definición tradicional de estadística:la colección, organización,resumen y presentación de datos numéricos.

Actualmente la Estadística es una rama de la matemática aplicada que colecciona, clasifica y evalúa o analiza datos como base para inferencias o conclusiones válidas, así como para tomar decisiones en base a ese análisis.

Como un procedimiento de toma de decisiones, la Estadística es de importancia creciente en varios campos, por ejemplo, en la producción industrial en masa, Medicina Y Biología, Economía, Política, Psicología, análisis de opinión pública y otras Ciencias Sociales, Agricultura, Meteorología, Física, Química e Ingeniería.

## 1.2 Relacion entre Estadistica y Probabilidad

La probabilidad es el estudio de fenómenos puramente aleatorios mientras que la Estadística se puede describir como la ciencia o el arte de reunir y analizar datos e inferir consecuencias a partir de estos elementos. Como el azar afecta tanto a la reunión de datos como a su análisis, y se debe tener en cuenta al hacer inferencias, el tener conocimientos en estadística implica poseer una buena base sobre la teoría de la probabilidad.

## 1.3 Sintesis de la Estadistica y de la Probabilidad

La teoría de la Probabilidad tuvo su origen en las apuestas en **juegos de azar**; a Girolamo Cardano (1501-1576), físico, astrónomo y maternatico, se le atribuye la primera discusión sobre probabilidad en su manual para jugadores; pero fueron **Pascal** (1623-1662) y **Fermat** (1600 -1665). alrededor de la primera mitad del **siglo XVII** quienes desarrollaron la **Teoría de la Probabilidad**,

**Jakob Bernoulli** (1654-1705) fue también uno de los primeros que estudiaron la probabilidad matemática; su nombre va asociado a varios conceptos matemáticos, como los Experimentos de Bernoulli en probabilidad.

La **curva normal** ha sido de gran importancia en el desarrollo de la estadística. La ecuación de esta curva fue publicada por primera vez en **1733** por **De Moivre**. Pero De Moivre no ten. .dea de su aplicación en obser vaciones experimentales y su publicación era desconocida hasta que **Karl Pearson** la encontró en una Biblioteca en **1924**. Sin embargo, esta ecuación también fue descubierta posteriormente por dos astrónomos y matemáticos: **Laplace** (1749-1827) y **Gauss** (1777-1855) independientemente, hoy en día se conoce también como la curva de Gauss o campana de Gauss.

En el siglo XIX **Charles Lyell** encontró aplicación de la Estadística a un problema de Geología. Entre 1830 y 1833 Lyell publicó tres vo- lúmenes sobre Geología donde establece la relación entre las rocas terciarias y sus respectivos nombres. El razonamiento de Lyell fue esencialmente estadístico. Una vez que se establecieron y aceptaron los nombres, el método fue casi totalmente olvidado. No han habido geólogos evolucionistas que investiguen si fueron usadas medidas discretas, implícitas en los nombres, o si usó un proceso continuo y, si podrá ser usado para hacer predicciones.

**Charles Darwin** (1809-1882), biólogo, recibió el segundo volumen de Lyell y se cree que su teoría fue influenciada por este libro. El trabajo de Darwin fue principalmente de naturaleza biométrica o estadística. También **Mendel** con su estudio de las plantas híbridas publicado en 1866 tenía un problema de tipo biométrico o estadístico.

Pafhuti Lvovich **Chevyshev** (1821-1894) contribuyó a la teoría de la probabilidad con la **Desigualdad de Chevyshev**, que debido a su generalidad resulta ser una herramienta teórica muy importante.

En el siglo XIX la necesidad de una profundización en las bases de la Estadística se hizo trascendental, **Karl Pearson** (1857-1936) físico- matemático inglés, inspirado en Darwin, aplicó sus matemáticas a la evolución. Pearson, considerado el **padre de la Estadística** pasó casi medio siglo haciendo una profunda investigación en Estadística, asi también fue el fundador de la revista "**Biometrika**" y de la Escuela de Estadística en Cambridge, Inglaterra ganando gran ímpetu el estudio de esta materia. A Karl Pearson se debe el estudio de la bondad de ajuste con la **distribución** $X^2$ y el **coeficiente de correlación** entre dos variables.

Mientras Karl Pearson trabajaba con grandes muestras, la teoría de las grandes muestras era inadecuada para los investigadores que tenían que trabajar con pequeñas muestras. Entre ellos estaba **W. S. Gosset** (1876- 1937), alumno de K. Pearson y científico de la Cervecería "**Guinness**". Los conocimientos matemáticos de Gosset mostraron haber sido insuficientes para el reto de encontrar distribuciones exactas de la desviación estándar de la muestra, del cociente de la media y la desviación estándar de una muestra y del coeficiente de correlación, estadígrafos con los cuales él comunmente trabajaba. Consecuentemente el recurrió a compilar y computar las distribuciones de frecuencias empíricas al tomar cartas de un paquete de cartas barajadas, Los resultados de estos trabajos aparecieron en la re vista "Biometrika" en **1908** bajo el seudónimo de "**student**". Hoy en día, la distribución **" t "** de estudent es una herramienta básica para los estadísticos y experimentadores y "estudiantizar" es una expresión común en Estadística. Ahora que el uso de la distribución t de student está mundialmente difundida es interesante notar que el astrónomo alemán Helmet había obtenido los mismos resultados teóricamente a principios de **1875**.

**Ronald Alymer Fisher (**1890-1962), especialista inglés en Genética y Estadística, fue influenciado por Karl Pearson y Gosset; hizo numerosas e importantes contribuciones a la Estadística, precisó métodos estádisticos para interpretar datos cuantitativos. En su trabajo sobre pruebas de hipótesis, desarrolló aplicaciones de la **distribución F**, por lo que lleva su nombre. Esta distribución se utiliza para probar hipótesis acerca de dos varíanzas de pequeñas muestras. También la **Z de Fisher** usada para probar hipótesis acerca del coeficiente de correlación lineal.

**J. Neyman** (1894- ) y E. S. **Pearson** (1895- ) presentaron una teoría de pruebas de hipótesis estadísticas en 1936 y 1938; esta teoría promovió considerablemente la investigación y, muchos de sus resultados son de gran utilidad práctica.

**William Feiler**, nacido en 1906, contribuyó a la teoría de la pro habilidad con su trabajo sobre el **Teorema del Limite Central** y las **cadenas de Markov**. Introdujo un nuevo tratamiento en su libro "An Introduction to Probability and its Aplications" (1961) que contiene muchos ejemplos que explican nuevas aplicaciones a los fenómenos biológicos, físicos y estadisticos.

**John von Neumann** (1909-1957) llevó a cabo la primera demostración del **teorema minimax**, base fundamental de la teoría de juegos, que fue propuesto primeramente por **Emile Borel** en 1921. También fue un pionero de la teoría de las computadoras, habiendo diseñado y construido el llamado **MANIAC** (analizador matemático, integrador numérico y computador) en e\] Instituto para Estudios Avanzados en Princeton en 19S2

**Abraham Wald (**1902-1950) en sus dos libros "Sequential Analysis" y "Statistical Decision Fuctions" alcanzó grandes logros en Estadística y sus aplicaciones.

Así, en este siglo es cuando se han desarrollado la mayoría de los métodos estadísticos que se usan en la actualidad,

## 1.4 Estadistica e Investigacion

La Estadística interviene en la investigación y/o el método científico, a través de la experimentación y observación. Esto es, las observaciones experimentales y conocimientos son partes integrantes del método científico y esos métodos invariablemente conducen al empleo de técnicas de la Estadística. Ya que la Estadística, cuando se usa adecuadamente, hace más eficientes las investigaciones, es aconsejable que los investigadores se familiaricen con las técnicas y conceptos básicos de esta ciencia tan útil.

El uso de la estadística como herramienta de la investigación no puede separarse de la planeación general del proyecto de investigación. Si un proyecto de investigación debe producir datos que van a ser tratados es- tadísticamente, entonces un método estadístico apropiado debe formar una parte integrante del diseño total. Nada contribuye más a la angustia de un estadístico que el investigador ingenuo que obtiene datos con la convicción alegre de que un método estadístico estará automáticamente disponible para ancalizarlos.

Aunque pueda parecer que está de más mencionarlo, un proyecto de investigación debe ser diseñado y planificado antes de efectuarse. Sin em- bargo, por muy evidente que parezca esto, los estadísticos conocen demasia- do bien al investigador que aporta muchos datos, obtenidos de una manera for\_ tuita y a menudo sin una idea precisa de por qué fueron obtenidos. En tales casos, es a veces el triste deber del estadístico comunicarle al investigador que sus esfuerzos fueron desperdiciados porque no hay una manera legi- tima de analizar sus datos.

## 1.5 Etapas de ina Investigacion Estadistica

1.- **Formulación del problema**: Para investigar con éxito un pro- blema dado, primero tenemos que crear conceptos precisos, formular pregun tas claras, e imponer limitaciones adecuadas al problema, tomando en cuen ta el tiempo y el dinero disponibles y la habilidad de los investigado- res. Si se fracasa en esta formulación, los datos compilados pueden ser irrelevantes o inadecuados.

Es bueno rocordar que la calidad de las conclusiones estadísti- cas depende de la corrección y precisión de los datos que, a su vez, de- penden de la exactitud en la formulación del prohlema. Las técnicas esta- dísticas, por muy refinadas y precisas que sean, no pueden ayudar a alcan zar decisiones si son aplicadas a datos inapropiados.

2.- **Diseño del experimento**. Muestro deseo es obtener un máximo de información empleando un mínimo de costo y tiempo. Esto implica, entre otras cosas, que debemos determinar el tamaño de muestra, o la cantidad y tipo de datos que resolverán más eficientemente el problema. A la vez, es te tamaño sera afectado por el método matemático empleado en la última etapa (5a. etapa), y tenemos que seleccionar este método al igual que uno para muestrear. Con respecto al último, debemos observar que no es fácil obtener selecciones que sean completamente aleatorias.

Obtener una muestra representativa es fundamental en teoría es- tadística. Supone preguntas como estas: ¿Qué tipo de datos debe recogerse? ¿Cómo deben ser compilados los datos? ¿De qué tamaño debe ser la muestra? Estas preguntas corresponden a lo que se conoce como diseño de muestras o diseño experimental. Debe tenerse cuidado al planificar y diseñar un expe rimento; de otro modo, puede que no lleguemos a alcanzar ninguna conclu- sión válida.

3 . - **Colección de datos y experimentación**: La compilación de da- tos se refiere a los métodos usados para obtener información pertinente de las unidades elementales introducidas en una muestra. Fin general, ésta es la parte que más tiempo consume en toda investigación que sea realizada. Esta debe sujetarse a reglas estrictas . De hecho, cuanto menos opiniones impongamos, serán mejores los resultados

4 . - **Tabulación y descripción de los resultados**: En esta etapa los datos experimentales deben ser ordenados en forma legible y se ilustran con representa ciones gráficas (diagramas o gráficas ) ; además se calculan medidas descriptivas para el tamaño promedio y la separación o dispersión de los valores de la muestra. Los procedimientos correspondientes son simples y serán discutidos en la parte III.

5.- **Ingererencia estadística formulación de la respuesta**: Al aplicar el método estadístico seleccionado en la etapa 2. obtenemos conclusiones a partir de la muestra, acerca de la población correspondiente (inferencia estadística ) , tomamos una decisión y formulamos la respuesta a nuestro problema.

No existe una fórmula mágica en estadística matemática que tome en cuenta todas las situaciones prácticas concebibles. Por lo cual es ne- cesario adquirir conocimientos generales de los métodos más importantes que sean útiles para hacer inferencias. En cada caso práctico debe estu- diarse con cuidado la naturaleza del problema específico, para estar seguros de que será escogido el método más apropiado.

## 1.6 Estadistica Descriptiva y Estadistica Inferencial

Los datos tal como se obtienen no nos proporcionan información suficiente para interpretar su significado por lo que tenemos que utilizar métodos descriptivos para d a r l e s mayor sentido o inferenciales para sacar conclusiones válidas sobre e l l o s . Estos métodos dependen del t i p o de datos que se tengan y de los resultados que se quieran obtener.

Los métodos descriptivos se emplean para esquematizar o mostrar los datos en forma ordenada y gráfica sin sacar conclusiones de ellos. Los métodos descriptivos se pueden usar tanto para muestras como para pobla- ciones mientras que los métodos inferenciales usan solamente muestras para inferir a partir de las primeras, las características de la población. Cuan do usamos Estadística Inferencial generalizamos a partir de las Caracterís- ticas de una muestra las de la población.

## 1.7 Poblacion y Muestra

Una población o Universo es un agregado o la totalidad de unida- des elementales tales como personas, empresas industriales, granjas o da- tos de cualquier clase acerca de los cuales se desea información. Una mues tra es una porción o subconjunto de unidades elementales extraídas de una población

## 1.8 Unidades Elementales y Observacion

Los individuos u objetos de una población que tienen una caracte\_ rística medible se llaman unidades elementales; definir una población es, en un sentido, limitar el contenido de las unidades elementales. Estas po- seen ciertas características, conocidas a veces como rasgos o propiedades, que pueden ser de naturaleza cualitativa o cuantitativa.

El término observación se usará para indicar cualquier clase de medida obtenida en la investigación, es decir, el resultado de observar o medir una unidad elemental, se llama observación; también se puede entender como el valor numérico de una característica cuantificable de una unidad elemental.

## 1.9 Sumatorias

Dado un conjunto de observaciones de alguna variable representada por $X_1, X_2,....,X_n$ , podemos expresar su suma $X_1+X_2+....+X_n$ en forma abre- viada como

$$
\sum_{i=1}^n X_i
$$

Esto se lee " suma de los $X_i$ desde i igual a 1 hasta n"

Ejemplo 1.1. Si $X_1=1, X_2=-3, X_3=\frac{1}{4}$ , entonces

$$
\sum_{i=1}^3 X_i = X_1 + X_2 + X_3 = 1+(-3) + \frac{1}{4} = - \frac{7}{4}
$$

**Propiedades de las Sumatorias**

1.  Si c es una constante cualquiera, entonces $\sum_{i=1}^n cX_i = c \sum_{i=1}^nX_i$

**Corolario**: Si c es una constante, entonces $\sum_{i=1}^n c = nc$

2.  \$\\sum\_{i=1}\^n (X_i + Y_i + Z_i) = \\sum\_{i=1}\^n X_i  + \\sum\_{i=1}\^n Y_i  + \\sum\_{i=1}\^n Z_i \$

Colorario: $\sum_{i=1}^n (X_i + C) = \sum_{i=1}^n X_i + nC$

Sumatorias Dobles:

Frecuentemente en estadística se desea cono- cer la interacción entre dos variables; asi por ejemplo, consideramos las 20 determinaciones de presión sanguínea sistólica tomadas a un individuo que participa en un programa ideado para estudiar fuentes e intensidades de variación de lecturas de la presión de la sangre. La presión de la san gre fue medida por 4 médicos en cada una de 5 visitas. Los datos se resu- men en la siguiente tabla.
